# -*- coding: utf-8 -*-
"""evaluate_original_model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PLUWX0Mn_9lXCZZmYNuCzQL_5_B8wSsa
"""

import pandas as pd
import torch
from torch.utils.data import Dataset, DataLoader
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from sklearn.metrics import accuracy_score, classification_report
from tqdm import tqdm

# 1. Load Data
df = pd.read_excel("/content/checking.xlsx")  # Replace with your path

# 2. Map labels to integers based on FinBERT's label order
label_map = {'neutral': 0, 'positive': 1, 'negative': 2}
df['label_num'] = df['sentiment'].str.lower().map(label_map)

# 3. Load Tokenizer and Model
model_name = "yiyanghkust/finbert-tone"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(model_name)

# 4. Set device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)
model.eval()

# 5. Custom Dataset
class HeadlineDataset(Dataset):
    def __init__(self, headlines, labels, tokenizer, max_len=128):
        self.headlines = headlines
        self.labels = labels
        self.tokenizer = tokenizer
        self.max_len = max_len

    def __len__(self):
        return len(self.headlines)

    def __getitem__(self, idx):
        encoding = self.tokenizer(
            self.headlines[idx],
            truncation=True,
            padding='max_length',
            max_length=self.max_len,
            return_tensors="pt"
        )
        return {
            'input_ids': encoding['input_ids'].squeeze(0),
            'attention_mask': encoding['attention_mask'].squeeze(0),
            'labels': torch.tensor(self.labels[idx], dtype=torch.long)
        }

# 6. Create Dataset & DataLoader
dataset = HeadlineDataset(
    df["headlines"].tolist(),
    df["label_num"].tolist(),
    tokenizer
)
loader = DataLoader(dataset, batch_size=16)

# 7. Prediction Loop
preds = []
true_labels = []

with torch.no_grad():
    for batch in tqdm(loader):
        input_ids = batch["input_ids"].to(device)
        attention_mask = batch["attention_mask"].to(device)
        labels = batch["labels"].to(device)

        outputs = model(input_ids=input_ids, attention_mask=attention_mask)
        logits = outputs.logits
        predictions = torch.argmax(logits, dim=1)

        preds.extend(predictions.cpu().tolist())
        true_labels.extend(labels.cpu().tolist())

# 8. Accuracy and Report
accuracy = accuracy_score(true_labels, preds)
print(f"\nAccuracy: {accuracy:.4f}\n")
print("Classification Report:")
print(classification_report(true_labels, preds, target_names=label_map.keys()))

