# -*- coding: utf-8 -*-
"""evaluate_fine_tuned_model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jL8WCDHdh3r054XjRvJaNRqt1Xu1RtzC
"""

import pandas as pd
df=pd.read_excel("/content/checking.xlsx")
df

df.isna().sum()

df.sentiment.value_counts()

label_mapping = {"neutral": 0, "positive": 1, "negative": 2}
df["label_num"] = df["sentiment"].map(label_mapping)
df

df = df.sample(frac=1).reset_index(drop=True)
df

import pandas as pd
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from sklearn.metrics import accuracy_score
from torch.utils.data import DataLoader, Dataset
from tqdm import tqdm
model_name = "kkkkkjjjjjj/results"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(model_name)


# Custom dataset
class HeadlineDataset(Dataset):
    def __init__(self, headlines, labels, tokenizer, max_len=128):
        self.headlines = headlines
        self.labels = labels
        self.tokenizer = tokenizer
        self.max_len = max_len

    def __len__(self):
        return len(self.headlines)

    def __getitem__(self, idx):
        encoding = self.tokenizer(
            self.headlines[idx],
            truncation=True,
            padding='max_length',
            max_length=self.max_len,
            return_tensors="pt"
        )
        return {
            'input_ids': encoding['input_ids'].squeeze(0),
            'attention_mask': encoding['attention_mask'].squeeze(0),
            'labels': torch.tensor(self.labels[idx])
        }

# Create DataLoader
dataset = HeadlineDataset(
    df["headlines"].tolist(),
    df["label_num"].tolist(),
    tokenizer
)
loader = DataLoader(dataset, batch_size=16)

# Predict
preds = []
true_labels = []

with torch.no_grad():
    for batch in tqdm(loader):
        input_ids = batch["input_ids"]
        attention_mask = batch["attention_mask"]
        labels = batch["labels"]

        outputs = model(input_ids=input_ids, attention_mask=attention_mask)
        logits = outputs.logits
        predictions = torch.argmax(logits, dim=1)

        preds.extend(predictions.tolist())
        true_labels.extend(labels.tolist())

# Accuracy
accuracy = accuracy_score(true_labels, preds)
print("Accuracy:", accuracy)

from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns
import matplotlib.pyplot as plt

cm = confusion_matrix(true_labels, preds)
sns.heatmap(cm, annot=True, fmt="d", xticklabels=label_mapping.keys(), yticklabels=label_mapping.keys())
plt.xlabel("Predicted")
plt.ylabel("True")
plt.title("Confusion Matrix")
plt.show()

print(classification_report(true_labels, preds, target_names=label_mapping.keys()))

