{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527,
     "referenced_widgets": [
      "73df5b6000b642608e3306d71fdf53b7",
      "2ba60a79c57441e9b80b35bf38e87c20",
      "f1b85865b89d431da938814d89431dd2",
      "15cfb6c1044148e582241afe45753388",
      "41b6318626874feb98d44aa7e5a94fa4",
      "40d743e59e5446f8b1535e6bc2263177",
      "c3cbddf4c4af457fb12b473e3454aa81",
      "20d3c724a42c4b1b82dc0c98020c41cc",
      "67349660462248c19766bdf5a91fe84a",
      "6126d0832bd2449e9e0284f1f1bd38cb",
      "a172599101f94ce4914d51b6510b6df2",
      "6f9e6b6d622342eda4b55d9523683cf2",
      "56da508b82034d05970ea31ad965b25f",
      "e86af8a3433c4d7c833edac226f89ae4",
      "283ceac08cef482f8bac82ee4785af7a",
      "ef3d3e3a085e4837904e50a323ca1f4b",
      "8dea6103d7354179aa3ad02eb509ce04",
      "1405c6f82cd74d739772ca0556bdf657",
      "6d0b64b7cbfa4058bd3c2bc1afb7afd7",
      "a0ba32249bec4e8ca7c2300895408f55",
      "41f26225b63b43e986baf07a6c8aa8c3",
      "6c091a47f890453daf24b68b2750f05b",
      "aecda383d04e4b5698e56e3622cec1a5",
      "460d898c35a04983a03f3ed95861c2d9",
      "d6ae2aa301454fd49faeffc73503805a",
      "7a57cbad992c4f06b4fb0f472770334e",
      "63d9a57ee0644287954e3b4b4a4504e0",
      "5ac4872270d441babd27a6372de9d572",
      "71cd14854d4c4b939e2266b3716d0a6f",
      "8d820b2838f84c7793c740442f15942e",
      "960fa4b49a5042c385e923384ad68b2d",
      "669d689a9ae64cb0990c0d1708c1ac66",
      "a8268d06c7d64310b464303dd2f94175",
      "60b490ed48c1441a9595920835a8432e",
      "009f98c56df443eeb7d41565c989a988",
      "7eb16f9266584be8b3681ed5c45f0b14",
      "cd81984f7db14a889f8706e63f1edd2b",
      "93117e5576c84f759523abbc33a71e22",
      "90642cf87a584d3a9d283ee1d8ed36e2",
      "f2889e33d4494610a6a25b27ff5edf5e",
      "db4244d864094f68949ff520bec2f28a",
      "8bb079babf5d4f93b1e191912e5c2b53",
      "59f40713499c4ecb8322780e4d19aa4f",
      "9cfa7a06623d4e02baa7833bda0021d7"
     ]
    },
    "id": "zIxLfZfuUxNp",
    "outputId": "c10277ca-cfbe-42b3-cd3d-43b1fb8261c4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73df5b6000b642608e3306d71fdf53b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/533 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f9e6b6d622342eda4b55d9523683cf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aecda383d04e4b5698e56e3622cec1a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/439M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 2/19 [00:00<00:05,  3.09it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60b490ed48c1441a9595920835a8432e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/439M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:02<00:00,  7.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.7133\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.72      0.58      0.64       100\n",
      "    positive       0.66      0.76      0.71       101\n",
      "    negative       0.76      0.80      0.78        92\n",
      "\n",
      "    accuracy                           0.71       293\n",
      "   macro avg       0.72      0.72      0.71       293\n",
      "weighted avg       0.72      0.71      0.71       293\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "df = pd.read_excel(\"/content/checking.xlsx\")\n",
    "\n",
    "\n",
    "label_map = {'neutral': 0, 'positive': 1, 'negative': 2}\n",
    "df['label_num'] = df['sentiment'].str.lower().map(label_map)\n",
    "\n",
    "model_name = \"yiyanghkust/finbert-tone\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "class HeadlineDataset(Dataset):\n",
    "    def __init__(self, headlines, labels, tokenizer, max_len=128):\n",
    "        self.headlines = headlines\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.headlines)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        encoding = self.tokenizer(\n",
    "            self.headlines[idx],\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_len,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "            'labels': torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "\n",
    "dataset = HeadlineDataset(\n",
    "    df[\"headlines\"].tolist(),\n",
    "    df[\"label_num\"].tolist(),\n",
    "    tokenizer\n",
    ")\n",
    "loader = DataLoader(dataset, batch_size=16)\n",
    "\n",
    "\n",
    "preds = []\n",
    "true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(loader):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=1)\n",
    "\n",
    "        preds.extend(predictions.cpu().tolist())\n",
    "        true_labels.extend(labels.cpu().tolist())\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(true_labels, preds)\n",
    "print(f\"\\nAccuracy: {accuracy:.4f}\\n\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(true_labels, preds, target_names=label_map.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5mPcn0nHVIP-"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
